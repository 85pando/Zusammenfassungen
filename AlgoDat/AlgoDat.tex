\documentclass{scrartcl}

\usepackage{Header}

\usepackage{hyperref} %for links
\usepackage{algorithmic} %for pseudocode

\begin{document}


\Gruppe{Stephan Heidinger}{AlgoDat - Zusammenfassung v0.1}
\Header{Algorithemn \& Datenstrukturen}{Wintersemester 2011/2012}{Stephan Heidinger}{}%leave last variable empty, else there will be aufgabenblatt überschrift

\begin{shaded}
Dieses Dokument wurde unter der Creative Commons - Namensnennung-NichtKommerziell-Weitergabe unter gleichen Bedingungen (\textbf{CC by-nc-sa}) veröffentlicht. Die Bedingungen finden sich unter \href{http://creativecommons.org/licenses/by-nc-sa/3.0/de}{diesem Link}. \\
\centerline{\includegraphics[scale=1]{../cc-by-nc-sa.png} }
\end{shaded}

\textit{Find any errors? Please send them back, I want to keep them!}

\section{Einführung}
\subsection{Auswahlproblem}
Ziel: "`Bestimme das $k$. kleinste Element von $n$ Elementen"' \\
Spezialfälle: $k=
\begin{cases}
1 & Minimumsuche \\
n & Maximumsuche \\
\lfloor \frac{n}{2} \rfloor & Median
\end{cases}$\\

Verschiedene Ansätze:
\begin{enumerate}
	\item Auswahl nach Sortieren
	\item Wiederholte Minimumsuche
	\item Aktualisierung einer vorläufigen Lösung
	\item Nutzen von Standartbibliotheken
\end{enumerate}
Bewertung ist schwer, bei $1$ und $4$ muss mehr über die Implementierung bekannt sein, bei allen Varianten muss zudem mehr über die Eingabe bekannt sein.

\subsection{Maschinenmodell}
Wie soll bewertet werden? Laufzeit in Sekunden? Hängt massgeblich ab von:
\begin{itemize}
	\item Programmiersprache
	\item Rechner (Aufbau, Taktfrequenz, Speicher, \dots)
	\item Eingabedaten
\end{itemize}

Müssen Bewertung unabhängig davon finden $\Rightarrow$ \textbf{Zählen von \emph{elementaren Schritten}}

\begin{shaded}
\textbf{Random Access Machine} \\

Maschinenmodell mit:

\begin{itemize}
	\item endliche Zahl an Speicherzellen für Programm
	\item abzählbar endliche Zahl von Speicherzellen für Daten
	\item endliche Zahl von Registern
	\item arithmetisch-logische Einheit (ALU)
\end{itemize}

Anweisungen:

\begin{itemize}
	\item Transportbefehle (Laden, Verschieben, Speichern)
	\item Sprungbefehle (bedingt, unbedingt; $\to$ Schleifen, Rekursionen)
	\item arithmetische und logische Vernküpfungen
\end{itemize}

\end{shaded}

\subsection{Komplexität}
Beschreiben Komplexität durch.
\begin{description}
	\item[Laufzeit:] Anahl Schritte (asymptotisch)
	\item[Speicherbedarf:] Anzahl benutzter Speicherzellen
\end{description}

\subsubsection{Definitionen}
\begin{enumerate}
	\item höchstens so schnell wachsen wie $f$, {\tiny langsamer und gleich als $f$}
	\begin{shaded}
	\[ \mathcal{O}(f(n)) = \left\lbrace g: \mathds{N}_0 \to \mathds{R}
	\begin{array}{c}
	\textrm{es gibt Konstanten } c,n_0>0 \textrm{ mit} \\
	\vert g(n) \vert \leq c \cdot \vert f(n) \vert \textrm{ für alle } n>n_0
	\end{array}
	\right\rbrace \]
	\end{shaded}
	\item mindestens so schnell wachsen wie $f$, {\tiny schneller und gleich als $f$}
	\begin{shaded}
	\[ \Omega (f(n)) = \left\lbrace g: \mathds{N}_0 \to \mathds{R}
	\begin{array}{c}
	\textrm{es gibt Konstanten } c,n_0>0 \textrm{ mit} \\
	c \cdot \vert g(n) \vert \geq \vert f(n) \vert \textrm{ für alle } n>n_0
	\end{array}
	\right\rbrace \]
	\end{shaded}
	\item genauso so schnell wachsen wie $f$
	\begin{shaded}
	\[ \Theta(f(n)) = \left\lbrace g: \mathds{N}_0 \to \mathds{R}
	\begin{array}{c}
	\textrm{es gibt Konstanten } c_1,c_2,n_0>0 \textrm{ mit} \\
	c_1 \leq \frac{\vert g(n) \vert}{\vert f(n) \vert} \leq c_2 \textrm{ für alle } n>n_0
	\end{array}
	\right\rbrace \]
	\end{shaded}
	\item die gegenüber $f$ verschwinden, {\tiny langsamer als $f$}
	\begin{shaded}
	\[ o(f(n)) = \left\lbrace g: \mathds{N}_0 \to \mathds{R}
	\begin{array}{c}
	\textrm{zu jedem } c>0 \textrm{ex. \emph{ein} } n_0>0 \textrm{ mit} \\
	c \cdot \vert g(n) \leq \vert f(n) \vert \textrm{ für alle } n>n_0
	\end{array}
	\right\rbrace \]
	\end{shaded}
	\item denen gegenüber $f$ verschwindet, {\tiny schneller als $f$}
	\begin{shaded}
	\[ \omega(f(n)) = \left\lbrace g: \mathds{N}_0 \to \mathds{R}
	\begin{array}{c}
	\textrm{zu jedem } c>0 \textrm{ex. \emph{ein} } n_0>0 \textrm{ mit} \\
	\vert g(n) \geq c \cdot \vert f(n) \vert \textrm{ für alle } n>n_0
	\end{array}
	\right\rbrace \]
	\end{shaded}
\end{enumerate}

\begin{shaded}
\[ \log_a{n} \leq \sqrt{n} \leq n^2 \leq n^3 \leq 1,1^n \leq 2^n \leq n! \leq n^n\]
\end{shaded}

\subsubsection{Satz}
\begin{enumerate}
	\item $g \in \mathcal{O}(f) $ genau dann, wenn $f \in \Omega(g) $
	\\ $g \in \Theta(f) $ genau dann, wenn $f \in \Theta(g) $
	\item $\log_b{n} \in \Theta (\log_2{n}) $ für alle $b>1$ \\
	"`Die Basis des Logarithmus spielt für das Wachstum keine Rolle"'
	\item $ (\log_2{n})^d \in o(n^\varepsilon) $ für alle $d \in \mathds{N}_0, \varepsilon>0$\\
	"`Logarithmen wachsen langsamer als alle Polynomialfunktionen "'
	\item $ n^d \in o((1+\varepsilon)^n) $ für alle $d\in \mathds{N}_0, \varepsilon>0$\\
	"` Exponentielles Wachstum ist immer schneller als polynomielles "'
	\item $ b^n \in o((b+\varepsilon)^n) $ für alle $b\geq 1, \varepsilon>0$ \\
	"` Jede Verringerung der Basis verlangt exponentielles Wachstum"'
	\item $ \binom{a}{b} \in \Theta(n^k)$
	\item $H_n := \sum^n_{k=1} \frac{1}{k} = \ln n + \mathcal{O}(1)$ {\tiny (harmonische Zahlen)}
	\item $n! = \sqrt{2\pi n} \cdot \left( \frac{n}{c}^n \right) \cdot \left( 1+\Theta \left( \frac{1}{n} \right) \right)$ {\tiny (Stirlingformel)}
\end{enumerate}

\section{Sortieren}
\subsubsection{Gütekriterien}
\begin{itemize}
	\item Laufzeit
	\item Speicherbedarf
	\item Stabilität (kein Vertauschen der Reihenfolge schon sortierter Elemente)
	\item u.U. getrennte Betrachtung von Anzahl Vergleiche $C(n)$ und Anzahl Umspeicherungen $M(n)$
\end{itemize}

\subsection{SelectionSort}
\subsubsection{Algorithmus}
Idee: Man nehme pro Durchlauf das kleinste Element heraus und mache das solange, bis das Quellarray leer ist.
%\begin{algorithmic}
%\FOR {$i=1,\dots,n-1$}
%\STATE {$m \gets i$}
%	\FOR {$j=i+1,\dots,n$}
%	\IF {$M[j] < M[m]$}
%	\STATE {$m\gets j$}
%	\ENDIF
%	\ENDFOR
%	{vertausche $M[i]$ und $M[m]$}
%\ENDFOR
%\end{algorithmic}

\subsubsection{Laufzeit}
\begin{align*}
\textrm{Anzahl Vergleiche:} & & C(n) &= n-1 + n-2 + \cdots + 1 = \sum_{n-1}^{i=i}i = \frac{n-1)\cdot n}{2} \\
\textrm{Anzahl Umspeicherungen:} & & M(n) &= 3\cdot (n-1)
\end{align*}
Laufzeit liegt damit in $\Theta(n^2)$
\subsubsection{Stabilität}
Da weiter vorne stehende Elemente hinter gleiche andere vertauscht werden können: \textbf{nicht stabil}

\subsection{Divide \& Conquer: QuickSort}
\begin{shaded}
\textbf{Divide \& Conquer:} \\ Zerteile Aufgabe in kleinere Aufgaben \& Löse diese rekursiv.
\end{shaded}

Idee: Wähle ein Element $p$ ("`Pivot"') und teile die anderen Elemente der Eingabe auf in :
\begin{description}
	\item[$M_1$:] die höchstens kleineren Elemente
	\item[$M_2$:] die größeren Elemente
\end{description}
Sortierung von $M$ erhält man nun durch Hintereinanderschalten von $M_1,p,M_2$
\subsubsection{Algorithmus}
Idee: Wähle Pivot und teile die Arrays dementsprechend auf.
%\begin{algorithmic}
%\STATE \texttt{quicksort(M,l,r)}
%\IF{$l<r$}
%\STATE {$i \gets l+1$} \\
%	{$j \gets r$} \\
%	{$p \gets M[l]$}
%	\WHILE{$i \leq j$}
%	\STATE \WHILE {$i \leq j$ \&\& $M[i]\leq p$}
%		\STATE {$i \gets i+1$}
%		\ENDWHILE
%		\WHILE {$i \leq j$ \&\& $M[j]\geq p$}
%		\STATE {$j \gets j-1$}
%		\ENDWHILE
%		\IF{$i<j$}
%		\STATE {vertausche M[i] und M[j]}
%		\ENDIF
%	\ENDWHILE
%	\IF {$l<j$}
%	\STATE {vertausche $M[l]$ und $M[j]$} \\
%		\texttt{quicksort($M,l,j-1$)}
%	\ENDIF
%	\IF {$j<r$}
%	\STATE {\texttt{quicksort(M,j+1,r)}}
%	\ENDIF
%\ENDIF
%\end{algorithmic}
\subsubsection{Laufzeit}
\begin{description}
	\item[im besten Fall:] $\Theta(n\log n)$
	\item[im schlechtesten Fall:] $\Theta(n^2)$ {\tiny (bereits sortierte Eingabe)}
	\item[mittlere Laufzeit:] $\Theta(n\log n)$
\end{description}
Eine zufällige Auswahl des Pivot führt zu einem Algorithmus, der im Mittel auch auf vorsortierten Eingaben schnell ist.

\subsection{Divide \& Conquer: MergeSort}
MergeSort quasi umgekehrt zu QuickSort: triviale Aufteilung, linearer Aufwand bei Rekombination
\subsubsection{Algorithmus}
%\begin{algorithmic}
%\STATE \texttt{mergesort(M,l,r)}
%\IF {$l<r$}
%\STATE {$m \gets \lfloor \frac{l+r-1}{2} \rfloor$} \\
%	\texttt{mergesort(M,l,m)} \\
%	\texttt{mergesort(M,m+1,r)} \\
%	{$i\gets l;\; j\gets m+1;\; k\gets l$}
%	\WHILE{$i\leq m$ \&\& $j\leq r$}
%	\STATE \IF {$M[i]\leq M[j]$}
%		\STATE {$M'[k] \gets M[i]$} \\
%			{$i\gets i+1$}
%		\ELSE
%		\STATE {$M'[k] \gets M[j]$} \\
%			$j\gets j+1$
%		\ENDIF \\
%		{$k \gets k+1$}
%	\ENDWHILE
%	\FOR {$h=i,\dots,m$}
%	\STATE {$M[k+(h-1)] \gets M[h]$}
%	\ENDFOR
%	\FOR {$h=l,\dots,k-1$}
%	\STATE {$M[h] \gets M'[h]$}
%	\ENDFOR
%\ENDIF
%\end{algorithmic}
\subsubsection{Laufzeit}
Laufzeit ist in $\Theta(n\log n)$ {\tiny (unabhängig von der Eingabe, dafür aber höherer Speicherbedarf)}

\subsection{HeapSort}
\subsubsection{Heap}
\begin{shaded}
\textbf{Heap-Bedingung:} \\ Für jeden Knoten gilt, dass der darin gespeicherte Wert nicht kleienr ist, als die beiden Werte in seinen Kindern.
\end{shaded}
\centerline{\input{images/heap-bedingung.tex}}

\textbf{Einfügen:} Das neue Objekt wird hinten ins Array eingefügt, dann wird es solange mit seinem Vorgänger vertauscht, bis die \emph{Heap-Bedingung} wiederhergestellt ist. \textbf{Laufzeit:} $\mathcal{O}(\log n)$
%\begin{algorithmic}
%\STATE \texttt{insert}
%\STATE {$i \gets n+1$}
%\WHILE {$i>1$ \&\& $M\left[\lfloor\frac{i}{2}\rfloor\right]<a$}
%\STATE {$M[i] \gets M\left[\lfloor\frac{i}{2}\rfloor\right]$} \\
%	{$i \gets \lfloor\frac{i}{2}\rfloor$}
%\ENDWHILE
%\STATE {$M[i] \gets a$}
%\end{algorithmic}

\textbf{ExtractMax:} Zum Entfernen wird das erste Element entfernt. Das letzte Element des Arrays wird an die Spitze gefüllt und "`versickert"' nun nach unten. Dies wird mittels "`heapify"' erreicht. \\

\textbf{heapify:} Lässt aktuelles Element nach unten "`sickern"', indem es den Platz mit dem Größeren der Kinder vertauscht.

%\begin{algorithmic}
%\STATE {$a\gets M[i]$} \\ {$j\gets 2\cdot i$}
%\WHILE {$j\leq r$}
%\STATE \IF {$j<r$ \&\& $M[j+1]>M[j]$}
%	\STATE %{$j \gets j+1$}
%	\ENDIF
%	\IF {$a<M[j]$}
%	\STATE {$M[i] \gets M[j]$} \\
%		{$i \gets j$} \\
%		{$j \gets 2\cdot i$}
%	\ELSE
%	\STATE {$j \gets r+1$}
%	\ENDIF
%\ENDWHILE
%\STATE {$M[i] \gets a$}
%\end{algorithmic}

%%%%%%%%%%%% Seite 25 (pdf) bzw 21 (script)

\subsubsection{Algorithmus}
Idee: Der Algorithmus teilt sich in 2 Phasen:
\begin{enumerate}
	\item Herstellen der Heap-Eigenschaft: \\
	Starten bei $\lfloor \frac{n}{2} \rfloor$, rufen hier \texttt{heapify} auf und gehen dann zu $\lfloor \frac{n}{2} \rfloor, \dots,1$
	\item Abbau des Heap (Maximumsuche und Vertauschen nach Hinten: \\
	Um Speicherplatz zu sparen wird im selben Array gearbeitet. Dazu wird immer das erste Element mit dem letzten Element des verleibenden Heapes vertauscht und dieses neue dann "`versickert"' mittels \texttt{heapify}. Danach wir der Heap um $1$ verkleinert.
\end{enumerate}

\subsubsection{Laufzeit}
Die Laufzeit ist $\mathcal{O}(n \log n)$.

\subsection{Untere Laufzeitschranke}
Frage: Wie schnell kann man überhaupt Sortieren {\tiny(bzw etwas machen)}. Sortieren kann auch als Entscheidungsbaum dargestellt werden. Anhand des ersten Vergleiches folgen weitere Vergleiche, abhängig vom ersten Vergleich. Das sind $n!$ Blätter und somit:
\begin{align*}
\log n! &= \log[n\cdot (n-1) \cdot \ldots \cdot 2 \cdot 1]\\
        &=\log \left[ \left( \frac{n}{2}^{\frac{n}{2}} \right) \right]
        &= \frac{n}{2}\cdot\log\frac{n}{2}
        &\in \Omega(n\log n)
\end{align*}
\begin{shaded}
Jedes allgemeine Sortierverfahren benötigt im schlechtesten Fall $\Omega(n\log n)$ Vergleiche.
\end{shaded}

\subsection{Sortierverfahren für spezielle Universen}
\subsubsection{BucketSort}
Annahme: Wollen nur reelle Zahlen sortieren. O.B.d.A. gilt $\mathcal{U}=(0,1]$.
Für die Zahlen $M=\{a_1,\ldots,a_m\}$ werden nun $n$ Buckets erstellt und jede Zahl in den entsprechenden Bucket geworfen. Die einzelnen Buckets werden dann mit einem anderen Verfahren sortiert. Daher ist BucketSort ein \emph{Hüllensortierverfahren}.
\paragraph{Laufzeit}
Die mittlere Laufzeit von Bucketsort ist in $\mathcal{O}(n)$

\subsubsection{CountingSort}
Annahme: Wollen ganzzahlige Zahlen sortieren: $\mathcal{U}\subseteq\mathds N_0=\{0,\ldots,n\}$. O.B.d.A. gilt $M=\{0,\ldots,k-1\}$. Es wird nun für jede Zahl $1,\ldots,n$ ein Bucket erstellt und die Zahlen dort einsortiert. Danach werden die nun sortierten Zahlen wieder zurück ins Ursprungsarray geführt. \\
Damit die evtl Zuordnung zu Daten erhalten bleibt, braucht es noch ein Zusatzarray, aus welchem diese Zuordnung nachher wieder abgelesen werden kann.
\paragraph{Laufzeit}
Die Laufzeit von CountingSort ist in $\mathcal{O}(n+k)$.
\paragraph{Stabilität}
Nicht stabil.

\subsubsection{RadixSort}
Angenommen wir wollen Zahlen sortieren aus $\mathcal{U}=\{0,\ldots,d-1\}$ und wir haben ein stabiles Sortierverfahren für die $d$-äre Darstellung. Dann sortieren wir nach den Stellen, von hinten nach vorne. $s$ ist die Anzahl der Stellen. {\tiny Als Sortierverfahren bietet sich CountingSort an.}
\paragraph{Laufzeit}
Die Laufzeit ist in $\Theta(s\cdot(n+d)$. {\tiny Ein großes $d$ (z.B. $d=256 \; \Rightarrow$ byteweise Aufteilung) lohnt sich, da dann $s$ klein wird.}

\subsubsection{RadixExchangeSort}
Annahme: Zahlen in Binärdarstellung, Partitionierung aufgrund der der jeweils aktuellen Binärziffer
\paragraph{Laufzeit}
Die Laufzeit ist $\Theta(s\cdot n)$. Besonders geeignet, wenn $s$ klein im Verhältnis zu $n$.
\paragraph{Stabilität}
Nicht stabil.













\end{document}
